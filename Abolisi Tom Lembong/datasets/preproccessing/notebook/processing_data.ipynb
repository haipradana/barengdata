{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b85f3d1b",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315b5585",
   "metadata": {},
   "source": [
    "i proccess this into 2 version:\n",
    "1. Sentiment analysis ready: just cleaning-light without remove stopwords.\n",
    "2. Advance cleaning -> for topic analysis, clustering, dll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e20eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70036afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../../processed/concat_data.csv')\n",
    "df2 = pd.read_csv('../../processed/concat_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8e6d7a",
   "metadata": {},
   "source": [
    "### slangword normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "293ce783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d6a2299",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../stopword/slangwords.txt', 'r', encoding='utf-8') as f:\n",
    "    slang_dict = json.load(f)\n",
    "    \n",
    "kamusalay_df = pd.read_csv('../stopword/new_kamusalay.csv', encoding='latin1', header=None, names=['slang', 'baku'])\n",
    "kamusalay_dict = dict(zip(kamusalay_df['slang'], kamusalay_df['baku']))\n",
    "\n",
    "def normalize_slang(text):\n",
    "    words = text.split()\n",
    "    words = [slang_dict.get(w, w) for w in words]\n",
    "    words = [kamusalay_dict.get(w, w) for w in words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42559eb",
   "metadata": {},
   "source": [
    "## Proccess for sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92fe2cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kusus untuk kasus Tom Lembong yang dikasih Abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kalo tom lebong menerima abolisi ini, berarti ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Menjadi bukti bahwa kebijakan hukum di negara ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Karuan bebasne AE pak..kok pegel2 sidang seng ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RUWET KAREPE DEWE KAKEAN DRAMA KOYOK JOKOWI, S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Kusus untuk kasus Tom Lembong yang dikasih Abo...\n",
       "1  Kalo tom lebong menerima abolisi ini, berarti ...\n",
       "2  Menjadi bukti bahwa kebijakan hukum di negara ...\n",
       "3  Karuan bebasne AE pak..kok pegel2 sidang seng ...\n",
       "4  RUWET KAREPE DEWE KAKEAN DRAMA KOYOK JOKOWI, S..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1996489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac58e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    # Ganti koma (dengan/tanpa spasi setelahnya) jadi satu spasi\n",
    "    text = re.sub(r',\\s*', ' ', text)\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[\\u0600-\\u06FF]', '', text) #arab\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text) # cina jpn\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = emoji.replace_emoji(text, replace=' ')\n",
    "    text = re.sub(r'(.)\\1+', r'\\1', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d3fcca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming using sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# cara pakai\n",
    "def stem_text(text):\n",
    "    return stemmer.stem(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20633cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum()\n",
    "\n",
    "# drop rows with null values\n",
    "df1 = df1.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5367453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3961/3961 [00:00<00:00, 10353.98it/s]\n"
     ]
    }
   ],
   "source": [
    "def half_clean(text):\n",
    "    text = clean_text(text)\n",
    "    text = normalize_slang(text)\n",
    "    # text = stem_text(text)\n",
    "    return text\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "df1['cleaned'] = df1['text'].progress_apply(half_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2d972b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kusus untuk kasus Tom Lembong yang dikasih Abo...</td>\n",
       "      <td>khusus untuk kasus tom lembong yang kasih abol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kalo tom lebong menerima abolisi ini, berarti ...</td>\n",
       "      <td>kalau tom lebong menerima abolisi ini berarti ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Menjadi bukti bahwa kebijakan hukum di negara ...</td>\n",
       "      <td>menjadi bukti bahwa kebijakan hukum di negara ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Karuan bebasne AE pak..kok pegel2 sidang seng ...</td>\n",
       "      <td>karuan bebasne saja pak kok pegal sidang seng ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RUWET KAREPE DEWE KAKEAN DRAMA KOYOK JOKOWI, S...</td>\n",
       "      <td>ruwet karepe sendiri kebanyakan drama koyok jo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Kusus untuk kasus Tom Lembong yang dikasih Abo...   \n",
       "1  Kalo tom lebong menerima abolisi ini, berarti ...   \n",
       "2  Menjadi bukti bahwa kebijakan hukum di negara ...   \n",
       "3  Karuan bebasne AE pak..kok pegel2 sidang seng ...   \n",
       "4  RUWET KAREPE DEWE KAKEAN DRAMA KOYOK JOKOWI, S...   \n",
       "\n",
       "                                             cleaned  \n",
       "0  khusus untuk kasus tom lembong yang kasih abol...  \n",
       "1  kalau tom lebong menerima abolisi ini berarti ...  \n",
       "2  menjadi bukti bahwa kebijakan hukum di negara ...  \n",
       "3  karuan bebasne saja pak kok pegal sidang seng ...  \n",
       "4  ruwet karepe sendiri kebanyakan drama koyok jo...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bef6e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forbidden_words = ['ùóóùó•ùóîùóöùó¢ùó°ùü≠ùü¥ùü≥_üÄÑ', 'web', 'jt', 'juta', 'wd', 'hokinya', 'hoki', 'putaranya', 'putaran', 'pecahannya', 'gcr', 'dragon187', 'ngewe', 'farhan', 'gajah', 'vcs', 'tengu', 'carlina', 'Carlina', 'usman', 'wasaf']\n",
    "\n",
    "# Fungsi cek apakah ada kata terlarang\n",
    "def contains_forbidden(text):\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "    return any(word in text.lower().split() for word in forbidden_words)\n",
    "\n",
    "# Hapus baris yang mengandung kata terlarang\n",
    "df1 = df1[~df1['text'].apply(contains_forbidden)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40132dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text       0\n",
       "cleaned    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69a61e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('../../processed/sentiment-ready.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b5bfa4",
   "metadata": {},
   "source": [
    "## Advance proccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cdb9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text2(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    # Ganti koma (dengan/tanpa spasi setelahnya) jadi satu spasi\n",
    "    text = re.sub(r',\\s*', ' ', text)\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[\\u0600-\\u06FF]', '', text) #arab\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text) # cina jpn\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\xFF]+', '', text)\n",
    "    # Hapus karakter non-alfanumerik kecuali spasi\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = emoji.replace_emoji(text, replace=' ')\n",
    "    # Hilangkan spasi berlebih\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Hilangkan huruf berulang (2x atau lebih)\n",
    "    text = re.sub(r'(.)\\1{1,}', r'\\1', text)\n",
    "    text = re.sub(r'(.)\\1+', r'\\1', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52dfdce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kusus untuk kasus Tom Lembong yang dikasih Abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kalo tom lebong menerima abolisi ini, berarti ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Menjadi bukti bahwa kebijakan hukum di negara ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Karuan bebasne AE pak..kok pegel2 sidang seng ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RUWET KAREPE DEWE KAKEAN DRAMA KOYOK JOKOWI, S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Kusus untuk kasus Tom Lembong yang dikasih Abo...\n",
       "1  Kalo tom lebong menerima abolisi ini, berarti ...\n",
       "2  Menjadi bukti bahwa kebijakan hukum di negara ...\n",
       "3  Karuan bebasne AE pak..kok pegel2 sidang seng ...\n",
       "4  RUWET KAREPE DEWE KAKEAN DRAMA KOYOK JOKOWI, S..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63ed3d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "957e1695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null values\n",
    "df2 = df2.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f03d5f",
   "metadata": {},
   "source": [
    "### Pakai stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a393e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../stopword/stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = set([line.strip() for line in f if line.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71e589f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    words = text.split()\n",
    "    filtered = [w for w in words if w not in stopwords]\n",
    "    return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61f05c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopword removal using Sastrawi\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "stop_factory = StopWordRemoverFactory()\n",
    "stopword = stop_factory.create_stop_word_remover()\n",
    "\n",
    "def remove_stopwords2(text):\n",
    "    return stopword.remove(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14931410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3961/3961 [04:28<00:00, 14.75it/s]\n"
     ]
    }
   ],
   "source": [
    "def full_clean(text):\n",
    "    text = clean_text2(text)\n",
    "    text = normalize_slang(text)\n",
    "    text = stem_text(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_stopwords2(text)\n",
    "    return text\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "df2['cleaned'] = df2['text'].progress_apply(full_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c182a87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kusus untuk kasus Tom Lembong yang dikasih Abo...</td>\n",
       "      <td>khusus kasus tom lembong kasih abolisi preside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kalo tom lebong menerima abolisi ini, berarti ...</td>\n",
       "      <td>tom lebong terima abolisi arti terima diangap ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Menjadi bukti bahwa kebijakan hukum di negara ...</td>\n",
       "      <td>jadi bukti bijak hukum negara formalitas publi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Karuan bebasne AE pak..kok pegel2 sidang seng ...</td>\n",
       "      <td>karuan bebasne pak pegal sidang seng demo seng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RUWET KAREPE DEWE KAKEAN DRAMA KOYOK JOKOWI, S...</td>\n",
       "      <td>ruwet karepe drama koyok jokowi sistem birokra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Kusus untuk kasus Tom Lembong yang dikasih Abo...   \n",
       "1  Kalo tom lebong menerima abolisi ini, berarti ...   \n",
       "2  Menjadi bukti bahwa kebijakan hukum di negara ...   \n",
       "3  Karuan bebasne AE pak..kok pegel2 sidang seng ...   \n",
       "4  RUWET KAREPE DEWE KAKEAN DRAMA KOYOK JOKOWI, S...   \n",
       "\n",
       "                                             cleaned  \n",
       "0  khusus kasus tom lembong kasih abolisi preside...  \n",
       "1  tom lebong terima abolisi arti terima diangap ...  \n",
       "2  jadi bukti bijak hukum negara formalitas publi...  \n",
       "3  karuan bebasne pak pegal sidang seng demo seng...  \n",
       "4  ruwet karepe drama koyok jokowi sistem birokra...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1fc3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[~df2['text'].apply(contains_forbidden)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d6c2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace all occurrences of 'wkwk' with an empty string in both 'text' and 'cleaned' columns\n",
    "# df2['text'] = df2['text'].str.replace('wkwk', '', regex=False)\n",
    "df2['cleaned'] = df2['cleaned'].str.replace('wkwk', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3acbb3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text       0\n",
       "cleaned    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e10ec031",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('../../processed/advanced-cleaning.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
